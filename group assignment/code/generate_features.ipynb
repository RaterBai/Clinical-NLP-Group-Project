{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:14.147603Z",
     "start_time": "2021-03-17T03:06:13.700175Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:14.890879Z",
     "start_time": "2021-03-17T03:06:14.718110Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../data/AnonymizedClinicalAbbreviationsAndAcronymsDataSet.txt\", \n",
    "                   encoding='cp1252', \n",
    "                   sep=\"|\", \n",
    "                   header=None,\n",
    "                   na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:15.826645Z",
     "start_time": "2021-03-17T03:06:15.824011Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns = [\"abbrev\", \"sense\", \"represntaion\", \"start_pos\", \"end_pos\", \"section_info\", \"sample\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:16.827003Z",
     "start_time": "2021-03-17T03:06:16.807301Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbrev</th>\n",
       "      <th>sense</th>\n",
       "      <th>represntaion</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>end_pos</th>\n",
       "      <th>section_info</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB.</td>\n",
       "      <td>231</td>\n",
       "      <td>233</td>\n",
       "      <td></td>\n",
       "      <td>_%#NAME#%_ _%#NAME#%_ is a 29-year-old gravida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB.</td>\n",
       "      <td>249</td>\n",
       "      <td>251</td>\n",
       "      <td></td>\n",
       "      <td>She is now bleeding quite heavily. Ultrasound ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB</td>\n",
       "      <td>223</td>\n",
       "      <td>224</td>\n",
       "      <td>PAST OB HISTORY</td>\n",
       "      <td>ALLERGIES: Heparin and Imitrex. PAST OB HISTOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB.</td>\n",
       "      <td>194</td>\n",
       "      <td>196</td>\n",
       "      <td>HISTORY OF THE PRESENT ILLNESS</td>\n",
       "      <td>She had a pelvic ultrasound at Park Nicollet o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>PAST OB-GYN HISTORY</td>\n",
       "      <td>On _%#MMDD2007#%_, normal anatomy with anterio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AB</td>\n",
       "      <td>ankle-brachial</td>\n",
       "      <td>AB</td>\n",
       "      <td>329</td>\n",
       "      <td>330</td>\n",
       "      <td>SIGNIFICANT FINDINGS</td>\n",
       "      <td>7. Laryngospasm. CONSULTANTS: 1. Nephrology. 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: _%#NAME#%_ _%#NAME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AB</td>\n",
       "      <td>blood group in ABO system</td>\n",
       "      <td>AB</td>\n",
       "      <td>292</td>\n",
       "      <td>293</td>\n",
       "      <td>PATIENT IDENTIFICATION</td>\n",
       "      <td>PATIENT IDENTIFICATION: _%#NAME#%_ _%#NAME#%_ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB</td>\n",
       "      <td>236</td>\n",
       "      <td>237</td>\n",
       "      <td>PAST MEDICAL HISTORY</td>\n",
       "      <td>PAST MEDICAL HISTORY: None except car accident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td></td>\n",
       "      <td>_%#NAME#%_ _%#NAME#%_ is a 25-year-old female ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abbrev                      sense represntaion start_pos end_pos  \\\n",
       "0     AB                   abortion          AB.       231     233   \n",
       "1     AB                   abortion          AB.       249     251   \n",
       "2     AB                   abortion           AB       223     224   \n",
       "3     AB                   abortion          AB.       194     196   \n",
       "4     AB                   abortion           AB       114     115   \n",
       "5     AB             ankle-brachial           AB       329     330   \n",
       "6     AB                   abortion           AB        98      99   \n",
       "7     AB  blood group in ABO system           AB       292     293   \n",
       "8     AB                   abortion           AB       236     237   \n",
       "9     AB                   abortion           AB        65      66   \n",
       "\n",
       "                     section_info  \\\n",
       "0                                   \n",
       "1                                   \n",
       "2                 PAST OB HISTORY   \n",
       "3  HISTORY OF THE PRESENT ILLNESS   \n",
       "4             PAST OB-GYN HISTORY   \n",
       "5            SIGNIFICANT FINDINGS   \n",
       "6      HISTORY OF PRESENT ILLNESS   \n",
       "7          PATIENT IDENTIFICATION   \n",
       "8            PAST MEDICAL HISTORY   \n",
       "9                                   \n",
       "\n",
       "                                              sample  \n",
       "0  _%#NAME#%_ _%#NAME#%_ is a 29-year-old gravida...  \n",
       "1  She is now bleeding quite heavily. Ultrasound ...  \n",
       "2  ALLERGIES: Heparin and Imitrex. PAST OB HISTOR...  \n",
       "3  She had a pelvic ultrasound at Park Nicollet o...  \n",
       "4  On _%#MMDD2007#%_, normal anatomy with anterio...  \n",
       "5  7. Laryngospasm. CONSULTANTS: 1. Nephrology. 2...  \n",
       "6  HISTORY OF PRESENT ILLNESS: _%#NAME#%_ _%#NAME...  \n",
       "7  PATIENT IDENTIFICATION: _%#NAME#%_ _%#NAME#%_ ...  \n",
       "8  PAST MEDICAL HISTORY: None except car accident...  \n",
       "9  _%#NAME#%_ _%#NAME#%_ is a 25-year-old female ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:17.980050Z",
     "start_time": "2021-03-17T03:06:17.959683Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_abbrev = np.unique(data.abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:18.804030Z",
     "start_time": "2021-03-17T03:06:18.801346Z"
    }
   },
   "outputs": [],
   "source": [
    "empty_dict = dict.fromkeys(['abbrev','number_sense'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:20.772320Z",
     "start_time": "2021-03-17T03:06:19.828239Z"
    }
   },
   "outputs": [],
   "source": [
    "abbrev_freq = pd.DataFrame(columns=[\"abbrev\", \"number_sense\", \"sense\", \"freq\", \"percentage\"])\n",
    "#abbrev_freq_dict = dict.fromkeys(['abbrev','number_sense'])\n",
    "\n",
    "count_list = []\n",
    "for abbrev in unique_abbrev:\n",
    "    piece = data.loc[data.abbrev == abbrev]\n",
    "    senses = np.unique(piece.sense)\n",
    "    count = len(np.unique(piece.sense))\n",
    "    for sense in senses:\n",
    "        count_sense = piece.loc[piece.sense == sense].shape[0]\n",
    "        percentage = count_sense/piece.shape[0]\n",
    "        new = pd.DataFrame({\"abbrev\" : [abbrev],\n",
    "                            \"number_sense\" : [count],\n",
    "                            \"sense\" : [sense],\n",
    "                            \"freq\" : [count_sense],\n",
    "                            \"percentage\" : [percentage]})\n",
    "        \n",
    "        abbrev_freq = pd.concat([abbrev_freq, new])\n",
    "    #count_list.append(count)\n",
    "    \n",
    "#abbrev_freq = pd.DataFrame({\"abbrev\" : unique_abbrev, \"number_sense\" : count_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:21.372583Z",
     "start_time": "2021-03-17T03:06:21.368161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AB', 'AC', 'ALD', 'AMA', 'ASA', 'AV', 'AVR', 'BAL', 'BK', 'BM',\n",
       "       'BMP', 'C&S', 'C3', 'C4', 'CA', 'CDI', 'CEA', 'CR', 'CTA', 'CVA',\n",
       "       'CVP', 'CVS', 'DC', 'DIP', 'DM', 'DT', 'EC', 'ER', 'ES', 'ET',\n",
       "       'FISH', 'FSH', 'GT', 'IA', 'IB', 'IM', 'IR', 'IT', 'ITP', 'IVF',\n",
       "       'LA', 'LE', 'MOM', 'MP', 'MR', 'MS', 'MSSA', 'NA', 'NAD', 'NP',\n",
       "       'OP', 'OR', 'OTC', 'PA', 'PAC', 'PCP', 'PD', 'PDA', 'PE', 'PM',\n",
       "       'PR', 'PT', 'RA', 'RT', 'SA', 'SBP', 'SMA', 'SS', 'T1', 'T2', 'T3',\n",
       "       'T4', 'US', 'VAD', 'VBG'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(abbrev_freq.abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:20:43.534721Z",
     "start_time": "2021-03-17T04:20:43.524890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abbrev</th>\n",
       "      <th>number_sense</th>\n",
       "      <th>sense</th>\n",
       "      <th>freq</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMA</td>\n",
       "      <td>3</td>\n",
       "      <td>advanced maternal age</td>\n",
       "      <td>31</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMA</td>\n",
       "      <td>3</td>\n",
       "      <td>against medical advice</td>\n",
       "      <td>444</td>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMA</td>\n",
       "      <td>3</td>\n",
       "      <td>antimitochondrial antibody</td>\n",
       "      <td>25</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abbrev number_sense                       sense freq  percentage\n",
       "0    AMA            3       advanced maternal age   31       0.062\n",
       "0    AMA            3      against medical advice  444       0.888\n",
       "0    AMA            3  antimitochondrial antibody   25       0.050"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbrev_freq.loc[abbrev_freq.abbrev == \"AMA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:23.278223Z",
     "start_time": "2021-03-17T03:06:23.276265Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "# if select AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:25.175881Z",
     "start_time": "2021-03-17T03:06:24.106005Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:22:47.664058Z",
     "start_time": "2021-03-17T03:22:47.639170Z"
    }
   },
   "outputs": [],
   "source": [
    "def derive_features(abbrev, window_size, replace = True):  # replace = True, replace numbers with zero\n",
    "    samples = data.loc[data.abbrev == abbrev, ]\n",
    "    sample_num = 1\n",
    "    \n",
    "    original_features = pd.DataFrame(columns=[\"id\", \"features\", \"sense\"])\n",
    "    direction_features = pd.DataFrame(columns=[\"id\", \"features\", \"sense\"])\n",
    "    direction_num_features = pd.DataFrame(columns=[\"id\", \"features\", \"sense\"])\n",
    "    \n",
    "    for i in range(samples.shape[0]):  # for each data point\n",
    "        sentence_num = 1\n",
    "        #target_word = samples.iloc[i, 2]  # should avoid using this, as word tokenization would split AC. to AC ., etc.\n",
    "        #target_word = abbrev\n",
    "        \n",
    "        text = samples.iloc[i, 6]\n",
    "        id = i+1  # this is the row number of selected abbreviation\n",
    "        sense = samples.iloc[i, 1]\n",
    "        \n",
    "        target_word = samples.iloc[i, 2]\n",
    "        sentence_length = 0\n",
    "        start_pos = int(samples.iloc[i, 3])\n",
    "        end_pos = int(samples.iloc[i, 4])\n",
    "        \n",
    "        target_word = text[start_pos : end_pos+1]\n",
    "        detect = True\n",
    "        #print(target_word)\n",
    "        # sentence boundary\n",
    "        # one sample can have multiple abbreviations in different sentences.\n",
    "        # before sentence boundary, replace all the numbers with 0 \n",
    "        #print(text)\n",
    "        \n",
    "        \n",
    "        #if replace:\n",
    "        #    text = re.sub(\"\\d+\", \"0\", text)\n",
    "        #    text = re.sub(\"\\d+\\.\\d+\", \"0\", text)\n",
    "\n",
    "        sents = sent_tokenize(text)\n",
    "        exclude = set(string.punctuation)\n",
    "        #s = ''.join(ch for ch in s if ch not in exclude)\n",
    "        for sent in sents:  # for each sentence\n",
    "            #words = [token.lower() for token in word_tokenize(sent)] # word tokenization\n",
    "            # remove punctuations from the words list\n",
    "            sentence_length += (len(sent)+1)\n",
    "            words = [word for word in word_tokenize(sent) if word not in string.punctuation]\n",
    "            \n",
    "#             print(id, \"____________________\")\n",
    "#             print(sent)\n",
    "#             print(words)\n",
    "#             print(target_word)\n",
    "#             print(sentence_length, end_pos)\n",
    "            if sentence_length >= end_pos and (abbrev in words or target_word in words) and detect:\n",
    "                #print(words)\n",
    "                #print(sent)\n",
    "                detect = False\n",
    "                left_features = []\n",
    "                right_features = []\n",
    "                \n",
    "                left_features_direction = []\n",
    "                right_features_direction = []\n",
    "                \n",
    "                left_features_direction_num = []\n",
    "                right_features_direction_num = []\n",
    "                \n",
    "                index = words.index(abbrev)\n",
    "                # find the targeted word\n",
    "                # 1. See if the window-size exceeds the front and back limit\n",
    "                    # If yes, start from the zero-th element, towards right till find the target (features on the left)\n",
    "                            # start from the max-th element, towards left till find the target (features on the right)\n",
    "                    # If no, start from the (index - 5)-th element, towards right till find the target\n",
    "                           # start from the (index - 5)-th element, towards left till find the target\n",
    "                        \n",
    "                # extract features on the left\n",
    "                if index - window_size < 0:\n",
    "                    j = 0\n",
    "                    starting = index\n",
    "                    #while words[j] != target_word:\n",
    "                    while words[j] != abbrev:\n",
    "                        words[j] = ''.join(ch for ch in words[j] if ch not in exclude)\n",
    "                        if replace:\n",
    "                            words[j] = re.sub(\"\\d+\", \"0\", words[j])\n",
    "                            words[j] = re.sub(\"\\d+\\.\\d+\", \"0\", words[j])\n",
    "                        # remove punctuation from the word, meant to fix problem in word tokenization\n",
    "                        # but may cause problem, e.g. p.r.n --> prn\n",
    "                        # may remove later\n",
    "                        \n",
    "                        left_features.append(words[j].lower())\n",
    "                        left_features_direction.append(\"L-\" + words[j].lower())\n",
    "                        left_features_direction_num.append(\"L\" + str(starting) + \"-\" + words[j].lower())\n",
    "                        j += 1\n",
    "                        starting -= 1\n",
    "                else:\n",
    "                    j = index-window_size\n",
    "                    starting = 0\n",
    "                    for k in range(window_size):\n",
    "                        words[j] = ''.join(ch for ch in words[j] if ch not in exclude)\n",
    "                        if replace:\n",
    "                            words[j] = re.sub(\"\\d+\", \"0\", words[j])\n",
    "                            words[j] = re.sub(\"\\d+\\.\\d+\", \"0\", words[j])\n",
    "                        left_features.append(words[j].lower())\n",
    "                        left_features_direction.append(\"L-\" + words[j].lower())\n",
    "                        left_features_direction_num.append(\"L\" + str(window_size-starting) + \"-\" + words[j].lower())\n",
    "                        j += 1\n",
    "                        starting += 1\n",
    "                \n",
    "                # extract feature on the right\n",
    "                if index + window_size >= len(words):\n",
    "                    #j = len(words)-1\n",
    "                    j = index+1\n",
    "                    starting = 1\n",
    "                    while j != len(words):\n",
    "                        words[j] = ''.join(ch for ch in words[j] if ch not in exclude)\n",
    "                        if replace:\n",
    "                            words[j] = re.sub(\"\\d+\", \"0\", words[j])\n",
    "                            words[j] = re.sub(\"\\d+\\.\\d+\", \"0\", words[j])\n",
    "                        right_features.append(words[j].lower())\n",
    "                        right_features_direction.append(\"R-\" + words[j].lower())\n",
    "                        right_features_direction_num.append(\"R\" + str(starting) + \"-\" + words[j].lower())\n",
    "                        j += 1\n",
    "                        starting += 1\n",
    "                else: \n",
    "                    j = index+1\n",
    "                    starting = 1\n",
    "                    for k in range(window_size):\n",
    "                        words[j] = ''.join(ch for ch in words[j] if ch not in exclude)\n",
    "                        if replace:\n",
    "                            words[j] = re.sub(\"\\d+\", \"0\", words[j])\n",
    "                            words[j] = re.sub(\"\\d+\\.\\d+\", \"0\", words[j])\n",
    "                        right_features.append(words[j].lower())\n",
    "                        right_features_direction.append(\"R-\" + words[j].lower())\n",
    "                        right_features_direction_num.append(\"R\" + str(starting) + \"-\" + words[j].lower())\n",
    "                        j += 1\n",
    "                        starting += 1\n",
    "                   \n",
    "                left_features_str = \" \".join(left_features)\n",
    "                right_features_str = \" \".join(right_features)\n",
    "                features = left_features_str + \" \" + right_features_str\n",
    "                \n",
    "#                 print(features)\n",
    "                \n",
    "                left_features_direction_str = \" \".join(left_features_direction)\n",
    "                right_features_direction_str = \" \".join(right_features_direction)\n",
    "                features_direction = left_features_direction_str + \" \" + right_features_direction_str\n",
    "                \n",
    "                left_features_direction_num_str = \" \".join(left_features_direction_num)\n",
    "                right_features_direction_num_str = \" \".join(right_features_direction_num)\n",
    "                features_direction_num = left_features_direction_num_str + \" \" + right_features_direction_num_str\n",
    "                #print(features_direction_num)\n",
    "                \n",
    "#                 if replace:\n",
    "#                     features = re.sub(\"\\d+\", \"0\", features)\n",
    "#                     features = re.sub(\"\\d+\\.\\d+\", \"0\", features)\n",
    "                    \n",
    "#                     features_direction = re.sub(\"\\d+\", \"0\", features_direction)\n",
    "#                     features_direction = re.sub(\"\\d+\\.\\d+\", \"0\", features_direction)\n",
    "                    \n",
    "#                     features_direction_num = features_direction_num+re.sub(\"\\d+\", \"0\", features_direction_num)\n",
    "#                     features_direction_num = features_direction_num+re.sub(\"\\d+\\.\\d+\", \"0\", features_direction_num)\n",
    "#                     print(features_direction_num)\n",
    "                original_features = pd.concat([original_features, pd.DataFrame({\"id\" : [id],\n",
    "                                                                               \"features\" : [features], \n",
    "                                                                               \"sense\" : [sense]})])\n",
    "                \n",
    "                direction_features = pd.concat([direction_features, pd.DataFrame({\"id\" : [id],\n",
    "                                                                               \"features\" : [features_direction], \n",
    "                                                                               \"sense\" : [sense]})])\n",
    "                \n",
    "                direction_num_features = pd.concat([direction_num_features, pd.DataFrame({\"id\" : [id],\n",
    "                                                                               \"features\" : [features_direction_num], \n",
    "                                                                               \"sense\" : [sense]})])\n",
    "            sentence_num += 1\n",
    "        sample_num += 1\n",
    "    return([original_features, direction_features, direction_num_features])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:22:58.529067Z",
     "start_time": "2021-03-17T04:22:56.557679Z"
    }
   },
   "outputs": [],
   "source": [
    "ar1, br1, cr1 = derive_features('AMA', 5, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE-HOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:23:00.188525Z",
     "start_time": "2021-03-17T04:23:00.176865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>features</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>L5-he L4-was L3-threatening L2-to L1-leave</td>\n",
       "      <td>against medical advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>L3-the L2-patient L1-left R1-on R2-the R3-morn...</td>\n",
       "      <td>against medical advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>L4-plan L3-patient L2-has L1-left R1-therefore...</td>\n",
       "      <td>against medical advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>antimitochondrial antibody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>L5-discharge L4-medications L3-craig L2-nystro...</td>\n",
       "      <td>against medical advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>496</td>\n",
       "      <td>L5-door L4-and L3-left L2-the L1-hospital</td>\n",
       "      <td>against medical advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>497</td>\n",
       "      <td>L3-discharge L2-plan L1-discharged</td>\n",
       "      <td>against medical advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>498</td>\n",
       "      <td>L5-and L4-rather L3-than L2-being L1-discharge...</td>\n",
       "      <td>against medical advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499</td>\n",
       "      <td>L5-upstairs L4-the L3-patient L2-had L1-left</td>\n",
       "      <td>against medical advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>L5-therefore L4-check L3-iron L2-studies L1-an...</td>\n",
       "      <td>antimitochondrial antibody</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                           features  \\\n",
       "0     1        L5-he L4-was L3-threatening L2-to L1-leave    \n",
       "0     2  L3-the L2-patient L1-left R1-on R2-the R3-morn...   \n",
       "0     3  L4-plan L3-patient L2-has L1-left R1-therefore...   \n",
       "0     4                                                      \n",
       "0     5  L5-discharge L4-medications L3-craig L2-nystro...   \n",
       "..  ...                                                ...   \n",
       "0   496         L5-door L4-and L3-left L2-the L1-hospital    \n",
       "0   497                L3-discharge L2-plan L1-discharged    \n",
       "0   498  L5-and L4-rather L3-than L2-being L1-discharge...   \n",
       "0   499      L5-upstairs L4-the L3-patient L2-had L1-left    \n",
       "0   500  L5-therefore L4-check L3-iron L2-studies L1-an...   \n",
       "\n",
       "                         sense  \n",
       "0       against medical advice  \n",
       "0       against medical advice  \n",
       "0       against medical advice  \n",
       "0   antimitochondrial antibody  \n",
       "0       against medical advice  \n",
       "..                         ...  \n",
       "0       against medical advice  \n",
       "0       against medical advice  \n",
       "0       against medical advice  \n",
       "0       against medical advice  \n",
       "0   antimitochondrial antibody  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:54:27.861035Z",
     "start_time": "2021-03-17T03:54:27.855154Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_features(abbrev, window_size, replace = True):\n",
    "    ar1, br1, cr1 = derive_features(abbrev, window_size, replace = True)\n",
    "    one_hot_vector=[]\n",
    "    for k in cr1['features'].values:\n",
    "        features_direction_num= [item for item in k.split(' ') if item !='']\n",
    "        one_hot_vector=one_hot_vector+features_direction_num\n",
    "    one_hot_vector=sorted(list(set(one_hot_vector)))\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(one_hot_vector))\n",
    "    onehot_encoded = list()\n",
    "    for k in cr1['features'].values:\n",
    "        features_direction_num= [item for item in k.split(' ') if item !='']\n",
    "        integer_encoded = [char_to_int[char] for char in features_direction_num]\n",
    "        # one hot encode\n",
    "\n",
    "        letter = [0 for _ in range(len(char_to_int))]\n",
    "        for value in integer_encoded:\n",
    "\n",
    "            letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    onehot_encoded=np.array(onehot_encoded)\n",
    "    return onehot_encoded,one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:22:18.630565Z",
     "start_time": "2021-03-17T04:22:08.917017Z"
    }
   },
   "outputs": [],
   "source": [
    "fea_5,name_5=one_hot_features('AMA', 5, replace=True)#not use ald as they have number of sense=1\n",
    "fea_4,name_4=one_hot_features('AMA', 4, replace=True)\n",
    "fea_3,name_3=one_hot_features('AMA', 3, replace=True)\n",
    "fea_2,name_2=one_hot_features('AMA', 2, replace=True)\n",
    "fea_1,name_1=one_hot_features('AMA', 1, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:22:22.473837Z",
     "start_time": "2021-03-17T04:22:22.470151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1391)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:22:23.627394Z",
     "start_time": "2021-03-17T04:22:23.621152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1-0',\n",
       " 'L1-a',\n",
       " 'L1-a0',\n",
       " 'L1-abbott',\n",
       " 'L1-advice',\n",
       " 'L1-an',\n",
       " 'L1-ana',\n",
       " 'L1-and',\n",
       " 'L1-as',\n",
       " 'L1-asma',\n",
       " 'L1-asthma',\n",
       " 'L1-by',\n",
       " 'L1-cbc',\n",
       " 'L1-center',\n",
       " 'L1-centers',\n",
       " 'L1-checking',\n",
       " 'L1-day',\n",
       " 'L1-department',\n",
       " 'L1-detox',\n",
       " 'L1-discharge',\n",
       " 'L1-discharged',\n",
       " 'L1-either',\n",
       " 'L1-evaluated',\n",
       " 'L1-facility',\n",
       " 'L1-for',\n",
       " 'L1-frequent',\n",
       " 'L1-from',\n",
       " 'L1-gerd',\n",
       " 'L1-go',\n",
       " 'L1-going',\n",
       " 'L1-her',\n",
       " 'L1-his',\n",
       " 'L1-home',\n",
       " 'L1-hospital',\n",
       " 'L1-hospitalization',\n",
       " 'L1-hours',\n",
       " 'L1-is',\n",
       " 'L1-labor',\n",
       " 'L1-last',\n",
       " 'L1-leave',\n",
       " 'L1-leaves',\n",
       " 'L1-leaving',\n",
       " 'L1-left',\n",
       " 'L1-name',\n",
       " 'L1-negative',\n",
       " 'L1-of',\n",
       " 'L1-or',\n",
       " 'L1-out',\n",
       " 'L1-patient',\n",
       " 'L1-point',\n",
       " 'L1-positive',\n",
       " 'L1-postdates',\n",
       " 'L1-pprom',\n",
       " 'L1-pregnancy',\n",
       " 'L1-room',\n",
       " 'L1-section',\n",
       " 'L1-sign',\n",
       " 'L1-signed',\n",
       " 'L1-signing',\n",
       " 'L1-so',\n",
       " 'L1-the',\n",
       " 'L1-them',\n",
       " 'L1-there',\n",
       " 'L1-to',\n",
       " 'L1-twice',\n",
       " 'L1-unit',\n",
       " 'L1-unity',\n",
       " 'L1-up',\n",
       " 'L1-was',\n",
       " 'L1-went',\n",
       " 'R1-',\n",
       " 'R1-0',\n",
       " 'R1-a',\n",
       " 'R1-after',\n",
       " 'R1-against',\n",
       " 'R1-although',\n",
       " 'R1-ana',\n",
       " 'R1-and',\n",
       " 'R1-antimitochondrial',\n",
       " 'R1-antismooth',\n",
       " 'R1-approximately',\n",
       " 'R1-as',\n",
       " 'R1-asma',\n",
       " 'R1-at',\n",
       " 'R1-basis',\n",
       " 'R1-because',\n",
       " 'R1-before',\n",
       " 'R1-but',\n",
       " 'R1-by',\n",
       " 'R1-complaining',\n",
       " 'R1-declined',\n",
       " 'R1-departure',\n",
       " 'R1-departures',\n",
       " 'R1-despite',\n",
       " 'R1-discharge',\n",
       " 'R1-does',\n",
       " 'R1-drawn',\n",
       " 'R1-due',\n",
       " 'R1-during',\n",
       " 'R1-earlier',\n",
       " 'R1-esr',\n",
       " 'R1-feeling',\n",
       " 'R1-form',\n",
       " 'R1-forms',\n",
       " 'R1-from',\n",
       " 'R1-given',\n",
       " 'R1-has',\n",
       " 'R1-he',\n",
       " 'R1-hemoglobin',\n",
       " 'R1-hepatitis',\n",
       " 'R1-her',\n",
       " 'R1-his',\n",
       " 'R1-history',\n",
       " 'R1-however',\n",
       " 'R1-i',\n",
       " 'R1-if',\n",
       " 'R1-in',\n",
       " 'R1-including',\n",
       " 'R1-increased',\n",
       " 'R1-infertility',\n",
       " 'R1-just',\n",
       " 'R1-knowing',\n",
       " 'R1-last',\n",
       " 'R1-late',\n",
       " 'R1-leave',\n",
       " 'R1-levels',\n",
       " 'R1-mainly',\n",
       " 'R1-medical',\n",
       " 'R1-mmdd0',\n",
       " 'R1-never',\n",
       " 'R1-not',\n",
       " 'R1-obesity',\n",
       " 'R1-on',\n",
       " 'R1-once',\n",
       " 'R1-or',\n",
       " 'R1-over',\n",
       " 'R1-papers',\n",
       " 'R1-paperwork',\n",
       " 'R1-previously',\n",
       " 'R1-prior',\n",
       " 'R1-protein',\n",
       " 'R1-rather',\n",
       " 'R1-readmitted',\n",
       " 'R1-secondary',\n",
       " 'R1-several',\n",
       " 'R1-she',\n",
       " 'R1-should',\n",
       " 'R1-since',\n",
       " 'R1-sma',\n",
       " 'R1-so',\n",
       " 'R1-spep',\n",
       " 'R1-stating',\n",
       " 'R1-status',\n",
       " 'R1-test',\n",
       " 'R1-the',\n",
       " 'R1-then',\n",
       " 'R1-there',\n",
       " 'R1-therefore',\n",
       " 'R1-this',\n",
       " 'R1-three',\n",
       " 'R1-to',\n",
       " 'R1-today',\n",
       " 'R1-ultrasound',\n",
       " 'R1-unable',\n",
       " 'R1-wanting',\n",
       " 'R1-was',\n",
       " 'R1-we',\n",
       " 'R1-when',\n",
       " 'R1-where',\n",
       " 'R1-which',\n",
       " 'R1-with',\n",
       " 'R1-within',\n",
       " 'R1-without',\n",
       " 'R1-would',\n",
       " 'R1-yesterday']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:23:17.066566Z",
     "start_time": "2021-03-17T04:23:17.063838Z"
    }
   },
   "outputs": [],
   "source": [
    "y=cr1['sense'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:23:25.337859Z",
     "start_time": "2021-03-17T04:23:25.334722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:39:13.213179Z",
     "start_time": "2021-03-17T03:39:13.211001Z"
    }
   },
   "outputs": [],
   "source": [
    "#one_hot_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# machine learning to decide window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:23:32.515600Z",
     "start_time": "2021-03-17T04:23:32.496231Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X_5, test_X_5, train_y, test_y = train_test_split(fea_5, y, test_size=0.2, random_state=13, shuffle=True, stratify=y)\n",
    "train_X_4, test_X_4, train_y, test_y = train_test_split(fea_4, y, test_size=0.2, random_state=13, shuffle=True, stratify=y)\n",
    "train_X_3, test_X_3, train_y, test_y = train_test_split(fea_3, y, test_size=0.2, random_state=13, shuffle=True, stratify=y)\n",
    "train_X_2, test_X_2, train_y, test_y = train_test_split(fea_2, y, test_size=0.2, random_state=13, shuffle=True, stratify=y)\n",
    "train_X_1, test_X_1, train_y, test_y = train_test_split(fea_1, y, test_size=0.2, random_state=13, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:30:34.124684Z",
     "start_time": "2021-03-17T04:30:34.119422Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def five_fold_CV(clf, params, dx, dy):\n",
    "    cv_model = RandomizedSearchCV(clf, params, scoring='f1_weighted', n_jobs=-1, \n",
    "                                  cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=13), \n",
    "                                  verbose=1, iid=True, n_iter=50, refit=True)\n",
    "    \n",
    "    cv_model.fit(dx, dy)\n",
    "    \n",
    "    return cv_model.best_estimator_, cv_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:27:30.831646Z",
     "start_time": "2021-03-17T04:27:30.827290Z"
    }
   },
   "outputs": [],
   "source": [
    "# use svm as a test\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=13)\n",
    "\n",
    "# define search space\n",
    "tuned_parameters = {\"C\": [0.001, 0.01, 0.1, 2, 8, 32, 64, 128, 512, 1024, 2048],\n",
    "                    'gamma':['scale', 'auto'],\n",
    "                    'probability':[True], \n",
    "                    'tol': [0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "#cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:54:42.621119Z",
     "start_time": "2021-03-17T04:54:42.616950Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "def report_result(y_test,predicted_target):\n",
    "#     print('precision',precision_score(y_test, predicted_target,average='macro'))\n",
    "#     print('f1',f1_score(y_test, predicted_target, average='macro'))\n",
    "#     print('recall',recall_score(y_test, predicted_target, average='macro'))\n",
    "    print('recall',accuracy_score(y_test, predicted_target))#recall should be accuracy if in WSD problem\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:31:11.764492Z",
     "start_time": "2021-03-17T04:30:46.456055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   24.3s finished\n",
      "/Users/zehao.yu/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=1024, gamma='auto', probability=True, random_state=13, tol=0.0001),\n",
       " 0.8985020384110807)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_model, best_cv_performance = five_fold_CV(svm, tuned_parameters, train_X_5, train_y)\n",
    "best_svm_model, best_cv_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:31:38.960234Z",
     "start_time": "2021-03-17T04:31:21.967227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   16.2s finished\n",
      "/Users/zehao.yu/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=1024, gamma='auto', probability=True, random_state=13),\n",
       " 0.9083878959888574)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_model, best_cv_performance = five_fold_CV(svm, tuned_parameters, train_X_4, train_y)\n",
    "best_svm_model, best_cv_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:31:48.575960Z",
     "start_time": "2021-03-17T04:31:38.962392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    9.2s finished\n",
      "/Users/zehao.yu/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=512, gamma='auto', probability=True, random_state=13, tol=0.1),\n",
       " 0.9260987095056243)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_model, best_cv_performance = five_fold_CV(svm, tuned_parameters, train_X_3, train_y)\n",
    "best_svm_model, best_cv_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:31:51.827231Z",
     "start_time": "2021-03-17T04:31:48.578250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 219 out of 250 | elapsed:    2.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.0s finished\n",
      "/Users/zehao.yu/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=512, gamma='auto', probability=True, random_state=13, tol=0.0001),\n",
       " 0.9161786650422198)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_model, best_cv_performance = five_fold_CV(svm, tuned_parameters, train_X_2, train_y)\n",
    "best_svm_model, best_cv_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:31:53.161626Z",
     "start_time": "2021-03-17T04:31:51.828777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    1.2s finished\n",
      "/Users/zehao.yu/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/sklearn/model_selection/_search.py:849: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SVC(C=2, probability=True, random_state=13, tol=0.0001), 0.9279876023360611)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm_model, best_cv_performance = five_fold_CV(svm, tuned_parameters, train_X_1, train_y)\n",
    "best_svm_model, best_cv_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:54:48.594216Z",
     "start_time": "2021-03-17T04:54:47.704862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.94\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=1024, gamma='auto', probability=True, random_state=13, tol=0.0001)\n",
    "clf.fit(train_X_5, train_y)\n",
    "predicted_target = clf.predict(test_X_5)\n",
    "report_result(test_y,predicted_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:57:25.880896Z",
     "start_time": "2021-03-17T04:57:25.217495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.94\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=1024, gamma='auto', probability=True, random_state=13)\n",
    "clf.fit(train_X_4, train_y)\n",
    "predicted_target = clf.predict(test_X_4)\n",
    "report_result(test_y,predicted_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:57:26.358408Z",
     "start_time": "2021-03-17T04:57:25.947744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.95\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=512, gamma='auto', probability=True, random_state=13, tol=0.1)\n",
    "clf.fit(train_X_3, train_y)\n",
    "predicted_target = clf.predict(test_X_3)\n",
    "report_result(test_y,predicted_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:57:26.928332Z",
     "start_time": "2021-03-17T04:57:26.683605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.95\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=512, gamma='auto', probability=True, random_state=13, tol=0.0001)\n",
    "clf.fit(train_X_2, train_y)\n",
    "predicted_target = clf.predict(test_X_2)\n",
    "report_result(test_y,predicted_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:57:27.375254Z",
     "start_time": "2021-03-17T04:57:27.258040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.91\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=2, probability=True, random_state=13, tol=0.0001)\n",
    "clf.fit(train_X_1, train_y)\n",
    "predicted_target = clf.predict(test_X_1)\n",
    "report_result(test_y,predicted_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can select 2 or 3 as window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T04:59:42.732453Z",
     "start_time": "2021-03-17T04:59:42.730501Z"
    }
   },
   "outputs": [],
   "source": [
    "#predicted_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T03:06:30.406286Z",
     "start_time": "2021-03-17T03:06:30.396689Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i+1 for i in range(500)]) - set(ar1.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = data.loc[data.abbrev == \"AB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The patient was asked to be seen for an Internal Medicine consult per Dr. _%#NAME#%_ _%#NAME#%_. HISTORY OF PRESENT ILLNESS: Patient _%#NAME#%_. is a 46-year-old female admitted to station 10-North from Fairview Ridges ER. The parents state that the patient has been having increasing symptoms of anxiety, paranoia and agitation the past several weeks.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab.iloc[483, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
